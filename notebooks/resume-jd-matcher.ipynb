{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b82be6f",
   "metadata": {},
   "source": [
    "# <center>**`Project Details`**</center>\n",
    "\n",
    "#### **Purpose**:\n",
    "\n",
    "Tis project goal is matching a resume to a job description. A poorly aligned resume can lead to missed opportunities, even when the candidate is a strong fit. The project aims to showcase how we can make use of AI agents to help applicants tailor their resumes more strategically, uncover hidden gaps, and present a stronger case to recruiters — all with minimal effort.\n",
    "\n",
    "A [Github repo](https://github.com/vikrambhat2/MultiAgents-with-CrewAI-ResumeJDMatcher) tackling this project exist and our goal will be to improve it by seperating the **Backend** and the **Frontend** logics.\n",
    "\n",
    "##### **Why Split**?\n",
    "\n",
    " - The backend will hold business logic, agent orchestration, model calls, state, data processing, API endpoints, while the frontend focuses on the UI/UX, user interaction, session management, file upload, displaying results.\n",
    " - Scalability: Backend can scale independently of UI (and can even serve other clients)\n",
    " - Security: Sensitive logic, API keys, and resource-intensive processing are kept server-side\n",
    " - Performance: Streamlit remains snappy, while heavy lifting is offloaded to backend\n",
    " \n",
    "##### **Responsibilities**\n",
    "\n",
    "  - *<u>Backend</u>*: \n",
    "    - Expose REST API endpoints:\n",
    "        - `/match`: Accepts resume + JD, returns match results and insights.\n",
    "        - `/enhance`: Accepts resume + JD, returns resume improvement suggestions.\n",
    "        - `/cover-letter`: Accepts resume + JD, returns a cover letter.\n",
    "    - Agent orchestration: All CrewAI workflows run here.\n",
    "    - Input validation, error handling.\n",
    "    - PDF/text parsing if desired (or can also be handled in frontend, see below).\n",
    "    - Optional: Authentication, user/session management, logging, monitoring.\n",
    "    - Optional: Serve as an async queue for heavy jobs if latency is an issue (using Celery/RQ, etc.).\n",
    " \n",
    " - *<u>Frontend</u>(Streamlit)*\n",
    "    - UI for uploading files, entering/pasting text.\n",
    "    - Visualization: Render reports, scores, enhanced resume, cover letter, etc.\n",
    "    - API client: Handles all interaction with FastAPI backend.\n",
    "    - Light preprocessing: E.g., local PDF parsing if you want to send plain text to backend (saves bandwidth).\n",
    "    - Session/user state, feedback, download links, etc.\n",
    "\n",
    "Here is how the system works (Flow):\n",
    "\n",
    " 1. User uploads resume & JD (PDF or text) → Streamlit UI\n",
    "\n",
    " 2. Frontend extracts or passes files → Sends to FastAPI (as text or file)\n",
    "\n",
    " 3. FastAPI endpoint receives, orchestrates CrewAI agents, returns structured results\n",
    "\n",
    " 4. Streamlit displays results, progress, suggestions, etc.\n",
    "\n",
    "#### **Constraints**:\n",
    "\n",
    " - None\n",
    "\n",
    "\n",
    "#### **Tools**:\n",
    "\n",
    " - Use local **ollama** model\n",
    "\n",
    "#### **Requirements**:\n",
    " - Make it work as expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7786816a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260bc82",
   "metadata": {},
   "source": [
    "## <center>**`Implementation`**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31c94b",
   "metadata": {},
   "source": [
    "## **`Backend`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c83de0",
   "metadata": {},
   "source": [
    "### Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465c415",
   "metadata": {},
   "source": [
    "#### PDF Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c604bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../backend/app/core/pdf_parser.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/pdf_parser.py\n",
    "\n",
    "#backend/app/core/pdf_parser.py\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "class PDFParser:\n",
    "    \"\"\"Handles PDF and plain text extraction.\"\"\"\n",
    "\n",
    "    def extract_text(self, file: Union[Path, bytes]) -> str:\n",
    "        if isinstance(file, Path):\n",
    "            with open(file, \"rb\") as f:\n",
    "                reader = PdfReader(f)\n",
    "                return self._extract_all(reader)\n",
    "        elif isinstance(file, bytes):\n",
    "            from io import BytesIO\n",
    "            reader = PdfReader(BytesIO(file))\n",
    "            return self._extract_all(reader)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type for PDFParser.\")\n",
    "        \n",
    "    def _extract_all(self, reader: PdfReader) -> str:\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7fa43",
   "metadata": {},
   "source": [
    "### Job Queueing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9c337e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/core/async_queue.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/async_queue.py\n",
    "# backend/app/core/async_queue.py\n",
    "import uuid\n",
    "\n",
    "class AsyncJobQueueDraft:\n",
    "    \"\"\"Draft for async job queue. Will later use Celery/RQ.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.jobs = {}\n",
    "\n",
    "    def submit_job(self, payload: dict) -> str:\n",
    "        job_id = str(uuid.uuid4())\n",
    "        self.jobs[job_id] = {\"status\": \"queued\", \"result\": None}\n",
    "        # In real queue: enqueue the job for background processing\n",
    "        return job_id\n",
    "    \n",
    "    def get_status(self, job_id: str) -> dict:\n",
    "        return self.jobs.get(job_id, {\"status\": \"not_found\", \"result\": None})\n",
    "    \n",
    "# Singleton\n",
    "queue = AsyncJobQueueDraft()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2d75e",
   "metadata": {},
   "source": [
    "### Backend api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2bde2",
   "metadata": {},
   "source": [
    "#### Data models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00fd2d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/models/job_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/models/job_models.py\n",
    "\n",
    "#backend/app/models/job_models.py\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "class ResumeJDRequest(BaseModel):\n",
    "    resume: Optional[str] = None\n",
    "    jd: Optional[str] = None\n",
    "\n",
    "class PDFUploadResponse(BaseModel):\n",
    "    extracted_text: str\n",
    "\n",
    "class JobSubmitResponse(BaseModel):\n",
    "    job_id: str\n",
    "\n",
    "class JobStatusResponse(BaseModel):\n",
    "    status: str\n",
    "    result: Optional[str] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553f032",
   "metadata": {},
   "source": [
    "#### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75847b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/api/routes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/api/routes.py\n",
    "#backend/app/api/routes.py\n",
    "\n",
    "from fastapi import APIRouter, File, UploadFile\n",
    "from backend.app.core.pdf_parser import PDFParser\n",
    "from backend.app.core.async_queue import queue\n",
    "from backend.app.models.job_models import(\n",
    "    ResumeJDRequest,\n",
    "    PDFUploadResponse,\n",
    "    JobSubmitResponse,\n",
    "    JobStatusResponse\n",
    ")\n",
    "\n",
    "\n",
    "api_router = APIRouter()\n",
    "\n",
    "@api_router.get(\"/health\", tags=[\"Health\"])\n",
    "def health_check():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@api_router.post(\"/parse-pdf\", response_model=PDFUploadResponse, tags=[\"Parsing\"])\n",
    "async def parse_pdf_endpoint(file: UploadFile = File(...)):\n",
    "    \"\"\"Extract text from uploaded PDF file.\"\"\"\n",
    "    content = await file.read()\n",
    "    parser = PDFParser()\n",
    "    try:\n",
    "        text = parser.extract_text(content)\n",
    "        return PDFUploadResponse(extracted_text=text)\n",
    "    except Exception as e:\n",
    "        return PDFUploadResponse(extracted_text=f\"Error: {str(e)}\")\n",
    "\n",
    "@api_router.post(\"/submit-job\", response_model=JobSubmitResponse, tags=[\"Jobs\"])\n",
    "async def submit_job(request: ResumeJDRequest):\n",
    "    \"\"\"Submit a matching/enhancing/cover letter job.\"\"\"\n",
    "    job_id = queue.submit_job(request.dict())\n",
    "    return JobSubmitResponse(job_id=job_id)\n",
    "\n",
    "@api_router.get(\"/job-status/{job_id}\", response_model=JobStatusResponse, tags=[\"Jobs\"])\n",
    "async def job_status(job_id: str):\n",
    "    status = queue.get_status(job_id)\n",
    "    return JobStatusResponse(**status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407815f",
   "metadata": {},
   "source": [
    "#### App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98164ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/main.py\n",
    "#backend/app/main.py\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from backend.app.api.routes import api_router\n",
    "\n",
    "class JDMatcherApp:\n",
    "    def __init__(self):\n",
    "        self.app = FastAPI(\n",
    "            title=\"Resume-JD Matcher API\",\n",
    "            description=\"Backend for matching candidate resumes to job descriptions using AI agents.\",\n",
    "            version=\"0.1.0\"\n",
    "        )\n",
    "        self.include_routers()\n",
    "\n",
    "\n",
    "    def include_routers(self):\n",
    "        self.app.include_router(api_router)\n",
    "\n",
    "def get_app():\n",
    "    \"\"\"Entrypoint for ASGI\"\"\"\n",
    "    return JDMatcherApp().app\n",
    "\n",
    "# Run with 'uvicorn backend.app.main:get_app'\n",
    "app = get_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c37969",
   "metadata": {},
   "source": [
    "## **`Frontend`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba83835",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-jd-matcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
