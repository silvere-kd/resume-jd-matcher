{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b82be6f",
   "metadata": {},
   "source": [
    "# <center>**`Project Details`**</center>\n",
    "\n",
    "#### **Purpose**:\n",
    "\n",
    "Tis project goal is matching a resume to a job description. A poorly aligned resume can lead to missed opportunities, even when the candidate is a strong fit. The project aims to showcase how we can make use of AI agents to help applicants tailor their resumes more strategically, uncover hidden gaps, and present a stronger case to recruiters — all with minimal effort.\n",
    "\n",
    "A [Github repo](https://github.com/vikrambhat2/MultiAgents-with-CrewAI-ResumeJDMatcher) tackling this project exist and our goal will be to improve it by seperating the **Backend** and the **Frontend** logics.\n",
    "\n",
    "##### **Why Split**?\n",
    "\n",
    " - The backend will hold business logic, agent orchestration, model calls, state, data processing, API endpoints, while the frontend focuses on the UI/UX, user interaction, session management, file upload, displaying results.\n",
    " - Scalability: Backend can scale independently of UI (and can even serve other clients)\n",
    " - Security: Sensitive logic, API keys, and resource-intensive processing are kept server-side\n",
    " - Performance: Streamlit remains snappy, while heavy lifting is offloaded to backend\n",
    " \n",
    "##### **Responsibilities**\n",
    "\n",
    "  - *<u>Backend</u>*: \n",
    "    - Expose REST API endpoints:\n",
    "        - `/match`: Accepts resume + JD, returns match results and insights.\n",
    "        - `/enhance`: Accepts resume + JD, returns resume improvement suggestions.\n",
    "        - `/cover-letter`: Accepts resume + JD, returns a cover letter.\n",
    "    - Agent orchestration: All CrewAI workflows run here.\n",
    "    - Input validation, error handling.\n",
    "    - PDF/text parsing if desired (or can also be handled in frontend, see below).\n",
    "    - Optional: Authentication, user/session management, logging, monitoring.\n",
    "    - Optional: Serve as an async queue for heavy jobs if latency is an issue (using Celery/RQ, etc.).\n",
    " \n",
    " - *<u>Frontend</u>(Streamlit)*\n",
    "    - UI for uploading files, entering/pasting text.\n",
    "    - Visualization: Render reports, scores, enhanced resume, cover letter, etc.\n",
    "    - API client: Handles all interaction with FastAPI backend.\n",
    "    - Light preprocessing: E.g., local PDF parsing if you want to send plain text to backend (saves bandwidth).\n",
    "    - Session/user state, feedback, download links, etc.\n",
    "\n",
    "Here is how the system works (Flow):\n",
    "\n",
    " 1. User uploads resume & JD (PDF or text) → Streamlit UI\n",
    "\n",
    " 2. Frontend extracts or passes files → Sends to FastAPI (as text or file)\n",
    "\n",
    " 3. FastAPI endpoint receives, orchestrates CrewAI agents, returns structured results\n",
    "\n",
    " 4. Streamlit displays results, progress, suggestions, etc.\n",
    "\n",
    "#### **Constraints**:\n",
    "\n",
    " - None\n",
    "\n",
    "\n",
    "#### **Tools**:\n",
    "\n",
    " - Use local **ollama** model\n",
    "\n",
    "#### **Requirements**:\n",
    " - Make it work as expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7786816a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260bc82",
   "metadata": {},
   "source": [
    "## <center>**`Implementation`**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31c94b",
   "metadata": {},
   "source": [
    "## **`Backend`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439699a4",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6880af07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/config.py\n",
    "# backend/app/config.py\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class Settings(BaseModel):\n",
    "    # LLM config\n",
    "    LLM_PROVIDER: str = Field(default=os.getenv(\"LLM_PROVIDER\", \"ollama\"))\n",
    "    LLM_API_KEY: str = Field(default=os.getenv(\"LLM_API_KEY\", \"ollama\"))\n",
    "    LLM_BASE_URL: str = Field(default=os.getenv(\"LLM_BASE_URL\", \"http://ollama:11434\"))\n",
    "    #LLM_BASE_URL: str = Field(default=os.getenv(\"LLM_BASE_URL\", \"http://host.docker.internal:11434\"))\n",
    "    LLM_MODEL_NAME: str = Field(default=os.getenv(\"LLM_MODEL_NAME\", \"llama3.2\"))\n",
    "    LLM_TEMPERATURE: str = Field(default=float(os.getenv(\"LLM_TEMPERATURE\", \"0.2\")))\n",
    "\n",
    "    # Celery/Redis\n",
    "    REDIS_URL: str = Field(default=os.getenv(\"REDIS_URL\", \"redis://host.docker.internal:6379/0\"))\n",
    "\n",
    "    def full_model_id(self) -> str:\n",
    "        \"\"\"\n",
    "        Return provider-prefixed model id for LiteLLM, e.g.:\n",
    "        - 'ollama/llama3.2'\n",
    "        - 'openai/gpt-4o-mini'\n",
    "        - 'groq/llama3-8b-8192'\n",
    "        \"\"\"\n",
    "        provider = self.LLM_PROVIDER.strip().lower()\n",
    "        # If already prefixed, keep as is\n",
    "        if \"/\" in self.LLM_MODEL_NAME:\n",
    "            return self.LLM_MODEL_NAME\n",
    "        return f\"{provider}/{self.LLM_MODEL_NAME}\"\n",
    "\n",
    "\n",
    "settings = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c83de0",
   "metadata": {},
   "source": [
    "### Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465c415",
   "metadata": {},
   "source": [
    "#### PDF Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c604bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/core/pdf_parser.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/pdf_parser.py\n",
    "\n",
    "#backend/app/core/pdf_parser.py\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "class PDFParser:\n",
    "    \"\"\"Handles PDF and plain text extraction.\"\"\"\n",
    "\n",
    "    def extract_text(self, file: Union[Path, bytes]) -> str:\n",
    "        if isinstance(file, Path):\n",
    "            with open(file, \"rb\") as f:\n",
    "                reader = PdfReader(f)\n",
    "                return self._extract_all(reader)\n",
    "        elif isinstance(file, bytes):\n",
    "            from io import BytesIO\n",
    "            reader = PdfReader(BytesIO(file))\n",
    "            return self._extract_all(reader)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type for PDFParser.\")\n",
    "        \n",
    "    def _extract_all(self, reader: PdfReader) -> str:\n",
    "        text = []\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text.append(page_text)\n",
    "        return \"\\n\".join(text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b22e748",
   "metadata": {},
   "source": [
    "#### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f958e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../backend/app/core/agents.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/agents.py\n",
    "# backend/app/core/agents.py\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "from crewai import Agent, LLM\n",
    "\n",
    "@dataclass\n",
    "class MatcherAgents:\n",
    "    resume_parser: Agent\n",
    "    jd_parser: Agent\n",
    "    matcher: Agent\n",
    "    enhancer: Agent\n",
    "    cover_letter: Agent\n",
    "\n",
    "class AgentsFactory:\n",
    "    \"\"\"Factory that builds all CrewAI agents with a shared LLM.\"\"\"\n",
    "    def __init__(self, llm: LLM):\n",
    "        self.llm = llm\n",
    "\n",
    "    def build(self) -> MatcherAgents:\n",
    "        resume_parser = Agent(\n",
    "            role=\"Resume Parsing Specialist\",\n",
    "            goal=\"Extract structured data (skills, experience, education, tools) from a resume.\",\n",
    "            backstory=\"You are meticulous and consistent. Output JSON only.\",\n",
    "            llm=self.llm,\n",
    "            verbose=False\n",
    "        )\n",
    "        jd_parser = Agent(\n",
    "            role=\"Job Description Analyst\",\n",
    "            goal=\"Extract required skills, responsibilities, and must-haves from a JD.\",\n",
    "            backstory=\"You identify core requirements and hiring signals. Output JSON only.\",\n",
    "            llm=self.llm,\n",
    "            verbose=False\n",
    "        )\n",
    "        matcher = Agent(\n",
    "            role=\"Resume-JD Matcher\",\n",
    "            goal=\"Compare parsed resume vs parsed JD. Score 0-100 and list strengths and gaps.\",\n",
    "            backstory=\"You are objective and concise. Output JSON only.\",\n",
    "            llm=self.llm,\n",
    "            verbose=False\n",
    "        )\n",
    "        enhancer = Agent(\n",
    "            role=\"Resume Enhancer\",\n",
    "            goal=\"Suggest resume improvements aligned with the JD and rewrite 3–5 key bullets.\",\n",
    "            backstory=\"Keep it ATS-friendly and specific. Output Markdown.\",\n",
    "            llm=self.llm,\n",
    "            verbose=False\n",
    "        )\n",
    "        cover_letter = Agent(\n",
    "            role=\"Cover Letter Writer\",\n",
    "            goal=\"Draft a tailored one-page cover letter aligned with resume and JD.\",\n",
    "            backstory=\"Professional, concise, concrete achievements. Output Markdown.\",\n",
    "            llm=self.llm,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        return MatcherAgents(\n",
    "            resume_parser=resume_parser,\n",
    "            jd_parser=jd_parser,\n",
    "            matcher=matcher,\n",
    "            enhancer=enhancer,\n",
    "            cover_letter=cover_letter\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df3f5f",
   "metadata": {},
   "source": [
    "#### Agent Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335df8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/core/agent_orchestrator.py\n"
     ]
    }
   ],
   "source": [
    "#%%writefile ../backend/app/core/agent_orchestrator.py\n",
    "\n",
    "# backend/app/core/agent_orchestrator.py\n",
    "from typing import Dict, Any\n",
    "from crewai import Task, Crew, LLM, Process\n",
    "from backend.app.config import settings\n",
    "from backend.app.core.agents import AgentsFactory\n",
    "\n",
    "class AgentOrchestrator:\n",
    "    \"\"\"Handles agent pipeline for resume-JD matching.\"\"\"\n",
    "    def __init__(self):\n",
    "        # We will build LLM here\n",
    "        model_id = settings.full_model_id()\n",
    "        self.llm = LLM(\n",
    "            model=model_id,\n",
    "            base_url=settings.LLM_BASE_URL,\n",
    "            api_key=settings.LLM_API_KEY,\n",
    "            temperature=settings.LLM_TEMPERATURE,\n",
    "        )\n",
    "\n",
    "    def _common_validate(self, data: Dict[str, Any]):\n",
    "        resume = (data or {}).get(\"resume\") or \"\"\n",
    "        jd = (data or {}).get(\"jd\") or \"\"\n",
    "        if not resume.strip() or not jd.strip():\n",
    "            raise ValueError(\"Both 'resume' and 'jd' text are required.\")\n",
    "        return resume, jd\n",
    "    \n",
    "    def _build_parsing_tasks(self, agents, resume: str, jd: str):\n",
    "        resume_task = Task(\n",
    "            description=f\"Extract structured JSON from the resume text below.\\nReturn keys: skills, experience, education, tools.\\n\\nRESUME:\\n{resume}\",\n",
    "            expected_output=\"Valid JSON with keys: skills, experience, education, tools.\",\n",
    "            agent=agents.resume_parser\n",
    "        )\n",
    "        jd_task = Task(\n",
    "            description=f\"Extract structured JSON from the job description below.\\nReturn keys: must_haves, nice_to_haves, responsibilities, keywords.\\n\\nJD:\\n{jd}\",\n",
    "            expected_output=\"Valid JSON with keys: must_haves, nice_to_haves, responsibilities, keywords.\",\n",
    "            agent=agents.jd_parser\n",
    "        )\n",
    "        return resume_task, jd_task\n",
    "\n",
    "    def run(self, job_type: str, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Executes the specified agent pipeline.\n",
    "        Args:\n",
    "            job_type: 'match', 'enhance', or 'cover_letter'\n",
    "            data: Dict with 'resume' and 'jd' (plain text)\n",
    "        Returns:\n",
    "            Dict with results\n",
    "        \"\"\"\n",
    "\n",
    "        job_type = (job_type or \"\").lower()\n",
    "        if job_type not in {\"match\", \"enhance\", \"cover_letter\"}:\n",
    "            raise ValueError(f\"Unsupported job_type: {job_type}\")\n",
    "        \n",
    "        resume, jd = self._common_validate(data)\n",
    "        agents = AgentsFactory(self.llm).build()\n",
    "\n",
    "        if job_type == \"match\":\n",
    "            resume_task, jd_task = self._build_parsing_tasks(agents, resume, jd)\n",
    "            match_task = Task(\n",
    "                description=\"Compare the parsed resume vs parsed JD and return a JSON with keys: \"\n",
    "                            \"- match_score: integer from 0-100, \" \\\n",
    "                            \"- strengths: list of matching skills from the resume and the JD, \" \\\n",
    "                            \"- gaps: list of gaps in the resume compared to the JD, \" \\\n",
    "                            \"- summary: string to summarize the evaluation.\",\n",
    "                expected_output=\"Valid JSON with keys: match_score, strengths, gaps, summary.\",\n",
    "                agent=agents.matcher,\n",
    "                context=[resume_task, jd_task]\n",
    "            )\n",
    "            crew = Crew(\n",
    "                agents=[agents.resume_parser, agents.jd_parser, agents.matcher],\n",
    "                tasks=[resume_task, jd_task, match_task],\n",
    "                process=Process.sequential,\n",
    "                verbose=False,\n",
    "                name=\"MatchCrew\",\n",
    "                description=\"Parses resume and JD, then computes a structured match report.\"\n",
    "            )\n",
    "            result = crew.kickoff()\n",
    "            return self._safe_parse_result(result, kind=\"match\")\n",
    "        \n",
    "        if job_type == \"enhance\":\n",
    "            resume_task, jd_task = self._build_parsing_tasks(agents, resume, jd)\n",
    "            enhance_task = Task(\n",
    "                description=\"Using parsed resume and JD, suggest concrete improvements and rewrite 3–5 bullets. \"\n",
    "                            \"Return Markdown with sections: 'Improvements' (bulleted) and 'Rewritten Bullets'.\",\n",
    "                expected_output=\"Markdown with 'Improvements' and 'Rewritten Bullets' sections.\",\n",
    "                agent=agents.enhancer,\n",
    "                context=[resume_task, jd_task]\n",
    "            )\n",
    "            crew = Crew(\n",
    "                agents=[agents.resume_parser, agents.jd_parser, agents.enhancer],\n",
    "                tasks=[resume_task, jd_task, enhance_task],\n",
    "                process=Process.sequential,\n",
    "                verbose=False,\n",
    "                name=\"EnhanceCrew\",\n",
    "                description=\"Parses resume and JD, then produces targeted enhancements.\"\n",
    "            )\n",
    "            result = crew.kickoff()\n",
    "            return {\"status\": \"done\", \"result\": {\"resume_enhancement_md\": getattr(result, \"raw\", str(result))}}\n",
    "\n",
    "        if job_type == \"cover_letter\":\n",
    "            resume_task, jd_task = self._build_parsing_tasks(agents, resume, jd)\n",
    "            cl_task = Task(\n",
    "                description=\"Draft a tailored one-page cover letter in Markdown based on parsed resume and JD.\",\n",
    "                expected_output=\"A Markdown-formatted cover letter.\",\n",
    "                agent=agents.cover_letter,\n",
    "                context=[resume_task, jd_task]\n",
    "            )\n",
    "            crew = Crew(\n",
    "                agents=[agents.resume_parser, agents.jd_parser, agents.cover_letter],\n",
    "                tasks=[resume_task, jd_task, cl_task],\n",
    "                process=Process.sequential,\n",
    "                verbose=False,\n",
    "                name=\"CoverLetterCrew\",\n",
    "                description=\"Parses resume and JD, then writes a tailored cover letter.\"\n",
    "            )\n",
    "            result = crew.kickoff()\n",
    "            return {\"status\": \"done\", \"result\": {\"cover_letter_md\": getattr(result, \"raw\", str(result))}}\n",
    "\n",
    "        raise RuntimeError(\"Unreachable branch.\")\n",
    "\n",
    "    def _safe_parse_result(self, crew_result, kind: str) -> Dict[str, Any]:\n",
    "        raw = getattr(crew_result, \"raw\", None)\n",
    "        if not raw:\n",
    "            return {\"status\": \"done\", \"result\": {\"raw\": str(crew_result)}}\n",
    "        # The matcher agent is instructed to output JSON, but we guard anyway.\n",
    "        try:\n",
    "            import json\n",
    "            parsed = json.loads(raw)\n",
    "            return {\"status\": \"done\", \"result\": parsed}\n",
    "        except Exception:\n",
    "            return {\"status\": \"done\", \"result\": {\"raw\": raw}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7fa43",
   "metadata": {},
   "source": [
    "### Job Queueing + Celery for distributed background job handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e7c4d",
   "metadata": {},
   "source": [
    "#### Queueing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9c337e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/core/async_queue.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/async_queue.py\n",
    "# backend/app/core/async_queue.py\n",
    "\n",
    "from celery.result import AsyncResult\n",
    "from backend.app.core.tasks import run_agent_job\n",
    "from backend.worker.worker import celery_app\n",
    "\n",
    "class AsyncJobQueueCelery:\n",
    "    \"\"\"Async job queue using Celery.\"\"\"\n",
    "    def submit_job(self, job_type: str, payload: dict) -> str:\n",
    "        # Ensure we don't pass 'job_type' twice (in task arg and inside payload)\n",
    "        clean_payload = dict(payload or {})\n",
    "        clean_payload.pop(\"job_type\", None)\n",
    "        celery_result = run_agent_job.delay(job_type, clean_payload)\n",
    "        return celery_result.id\n",
    "    \n",
    "    def get_status(self, job_id: str) -> dict:\n",
    "        result = AsyncResult(job_id, app=celery_app)\n",
    "        status = result.status\n",
    "        value = result.result if result.successful() else None\n",
    "        return {\"status\": status, \"result\": value}\n",
    "    \n",
    "# Singleton\n",
    "queue = AsyncJobQueueCelery()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bca06",
   "metadata": {},
   "source": [
    "#### Celery config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ce82233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/celeryconfig.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/celeryconfig.py\n",
    "# backend/celeryconfig.py\n",
    "\n",
    "import os\n",
    "\n",
    "# redis is in another docker container\n",
    "# if it's not the case for you,\n",
    "# use : \"redis://localhost:6379/0\"\n",
    "\n",
    "BROKER_URL = os.getenv(\"CELERY_BROKER_URL\", \"redis://host.docker.internal:6379/0\")\n",
    "RESULT_BACKEND = os.getenv(\"CELERY_RESULT_BACKEND\", BROKER_URL)\n",
    "\n",
    "broker_url = BROKER_URL\n",
    "result_backend = RESULT_BACKEND\n",
    "\n",
    "\n",
    "task_serializer = \"json\"\n",
    "result_serializer = \"json\"\n",
    "accept_content = [\"json\"]\n",
    "timezone = \"UTC\"\n",
    "enable_utc = True\n",
    "\n",
    "# Optional routing example (future: create dedicated queues)\n",
    "task_queues = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a8c16",
   "metadata": {},
   "source": [
    "#### Celery worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e13470b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/worker/worker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/worker/worker.py\n",
    "# backend/worker/worker.py\n",
    "\n",
    "from celery import Celery\n",
    "\n",
    "# Create Celery app\n",
    "celery_app = Celery(\"resume_jd_matcher\")\n",
    "celery_app.config_from_object(\"backend.celeryconfig\")\n",
    "\n",
    "# Ensure tasks are imported on worker start\n",
    "import backend.app.core.tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508076a0",
   "metadata": {},
   "source": [
    "#### Celery Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bac8c1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/core/tasks.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/tasks.py\n",
    "# backend/app/core/tasks.py\n",
    "\n",
    "from celery.utils.log import get_task_logger\n",
    "from backend.worker.worker import celery_app\n",
    "from backend.app.core.agent_orchestrator import AgentOrchestrator\n",
    "\n",
    "logger = get_task_logger(__name__)\n",
    "\n",
    "@celery_app.task(\n",
    "    name=\"run_agent_job\",\n",
    "    bind=False,\n",
    "    autoretry_for=(Exception,),\n",
    "    retry_backoff=True,\n",
    "    retry_jitter=True,\n",
    "    retry_kwargs={\"max_retries\": 3},\n",
    "    soft_time_limit=180,  # seconds\n",
    "    time_limit=240        # hard limit)\n",
    ")\n",
    "def run_agent_job(job_type: str, data: dict):\n",
    "    logger.info(\"Starting job type=%s\", job_type)\n",
    "    orchestrator = AgentOrchestrator()\n",
    "    result = orchestrator.run(job_type, data or {})\n",
    "    logger.info(\"Finished job type=%s\", job_type)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2d75e",
   "metadata": {},
   "source": [
    "### Backend api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2bde2",
   "metadata": {},
   "source": [
    "#### Data models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fd2d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/models/job_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/models/job_models.py\n",
    "\n",
    "#backend/app/models/job_models.py\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Dict\n",
    "\n",
    "class ResumeJDRequest(BaseModel):\n",
    "    job_type: str = Field(..., description=\"One of: match, enhance, cover_letter\")\n",
    "    resume: Optional[str] = Field(default=None, description=\"Plain text resume\")\n",
    "    jd: Optional[str] = Field(default=None, description=\"Plain text job description\")\n",
    "\n",
    "class PDFUploadResponse(BaseModel):\n",
    "    extracted_text: str\n",
    "\n",
    "class JobSubmitResponse(BaseModel):\n",
    "    job_id: str\n",
    "\n",
    "class JobStatusResponse(BaseModel):\n",
    "    status: str\n",
    "    result: Optional[Dict] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553f032",
   "metadata": {},
   "source": [
    "#### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75847b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/api/routes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/api/routes.py\n",
    "#backend/app/api/routes.py\n",
    "\n",
    "from fastapi import APIRouter, File, UploadFile\n",
    "from backend.app.core.pdf_parser import PDFParser\n",
    "from backend.app.core.async_queue import queue\n",
    "from backend.app.models.job_models import(\n",
    "    ResumeJDRequest,\n",
    "    PDFUploadResponse,\n",
    "    JobSubmitResponse,\n",
    "    JobStatusResponse\n",
    ")\n",
    "\n",
    "\n",
    "api_router = APIRouter()\n",
    "\n",
    "@api_router.get(\"/health\", tags=[\"Health\"])\n",
    "def health_check():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@api_router.post(\"/parse-pdf\", response_model=PDFUploadResponse, tags=[\"Parsing\"])\n",
    "async def parse_pdf_endpoint(file: UploadFile = File(...)):\n",
    "    \"\"\"Extract text from uploaded PDF file.\"\"\"\n",
    "    content = await file.read()\n",
    "    parser = PDFParser()\n",
    "    text = parser.extract_text(content)\n",
    "    return PDFUploadResponse(extracted_text=text)\n",
    "\n",
    "@api_router.post(\"/submit-job\", response_model=JobSubmitResponse, tags=[\"Jobs\"])\n",
    "async def submit_job(request: ResumeJDRequest):\n",
    "    \"\"\"Submit a matching/enhancing/cover letter job.\"\"\"\n",
    "    job_id = queue.submit_job(request.job_type, request.dict())\n",
    "    return JobSubmitResponse(job_id=job_id)\n",
    "\n",
    "@api_router.get(\"/job-status/{job_id}\", response_model=JobStatusResponse, tags=[\"Jobs\"])\n",
    "async def job_status(job_id: str):\n",
    "    status = queue.get_status(job_id)\n",
    "    return JobStatusResponse(**status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407815f",
   "metadata": {},
   "source": [
    "#### App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98164ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/main.py\n",
    "#backend/app/main.py\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from backend.app.api.routes import api_router\n",
    "\n",
    "class JDMatcherApp:\n",
    "    def __init__(self):\n",
    "        self.app = FastAPI(\n",
    "            title=\"Resume-JD Matcher API\",\n",
    "            description=\"Backend for matching candidate resumes to job descriptions using AI agents.\",\n",
    "            version=\"0.1.0\"\n",
    "        )\n",
    "        self.include_routers()\n",
    "\n",
    "\n",
    "    def include_routers(self):\n",
    "        self.app.include_router(api_router)\n",
    "\n",
    "def get_app():\n",
    "    \"\"\"Entrypoint for ASGI\"\"\"\n",
    "    return JDMatcherApp().app\n",
    "\n",
    "# Run with 'uvicorn backend.app.main:get_app'\n",
    "app = get_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c37969",
   "metadata": {},
   "source": [
    "## **`Frontend`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba83835",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-jd-matcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
