{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b82be6f",
   "metadata": {},
   "source": [
    "# <center>**`Project Details`**</center>\n",
    "\n",
    "#### **Purpose**:\n",
    "\n",
    "Tis project goal is matching a resume to a job description. A poorly aligned resume can lead to missed opportunities, even when the candidate is a strong fit. The project aims to showcase how we can make use of AI agents to help applicants tailor their resumes more strategically, uncover hidden gaps, and present a stronger case to recruiters — all with minimal effort.\n",
    "\n",
    "A [Github repo](https://github.com/vikrambhat2/MultiAgents-with-CrewAI-ResumeJDMatcher) tackling this project exist and our goal will be to improve it by seperating the **Backend** and the **Frontend** logics.\n",
    "\n",
    "##### **Why Split**?\n",
    "\n",
    " - The backend will hold business logic, agent orchestration, model calls, state, data processing, API endpoints, while the frontend focuses on the UI/UX, user interaction, session management, file upload, displaying results.\n",
    " - Scalability: Backend can scale independently of UI (and can even serve other clients)\n",
    " - Security: Sensitive logic, API keys, and resource-intensive processing are kept server-side\n",
    " - Performance: Streamlit remains snappy, while heavy lifting is offloaded to backend\n",
    " \n",
    "##### **Responsibilities**\n",
    "\n",
    "  - *<u>Backend</u>*: \n",
    "    - Expose REST API endpoints:\n",
    "        - `/match`: Accepts resume + JD, returns match results and insights.\n",
    "        - `/enhance`: Accepts resume + JD, returns resume improvement suggestions.\n",
    "        - `/cover-letter`: Accepts resume + JD, returns a cover letter.\n",
    "    - Agent orchestration: All CrewAI workflows run here.\n",
    "    - Input validation, error handling.\n",
    "    - PDF/text parsing if desired (or can also be handled in frontend, see below).\n",
    "    - Optional: Authentication, user/session management, logging, monitoring.\n",
    "    - Optional: Serve as an async queue for heavy jobs if latency is an issue (using Celery/RQ, etc.).\n",
    " \n",
    " - *<u>Frontend</u>(Streamlit)*\n",
    "    - UI for uploading files, entering/pasting text.\n",
    "    - Visualization: Render reports, scores, enhanced resume, cover letter, etc.\n",
    "    - API client: Handles all interaction with FastAPI backend.\n",
    "    - Light preprocessing: E.g., local PDF parsing if you want to send plain text to backend (saves bandwidth).\n",
    "    - Session/user state, feedback, download links, etc.\n",
    "\n",
    "Here is how the system works (Flow):\n",
    "\n",
    " 1. User uploads resume & JD (PDF or text) → Streamlit UI\n",
    "\n",
    " 2. Frontend extracts or passes files → Sends to FastAPI (as text or file)\n",
    "\n",
    " 3. FastAPI endpoint receives, orchestrates CrewAI agents, returns structured results\n",
    "\n",
    " 4. Streamlit displays results, progress, suggestions, etc.\n",
    "\n",
    "#### **Constraints**:\n",
    "\n",
    " - None\n",
    "\n",
    "\n",
    "#### **Tools**:\n",
    "\n",
    " - Use local **ollama** model\n",
    "\n",
    "#### **Requirements**:\n",
    " - Make it work as expected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7786816a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260bc82",
   "metadata": {},
   "source": [
    "## <center>**`Implementation`**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb31c94b",
   "metadata": {},
   "source": [
    "## **`Backend`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c83de0",
   "metadata": {},
   "source": [
    "### Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465c415",
   "metadata": {},
   "source": [
    "#### PDF Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c604bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../backend/app/core/pdf_parser.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/pdf_parser.py\n",
    "\n",
    "#backend/app/core/pdf_parser.py\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "class PDFParser:\n",
    "    \"\"\"Handles PDF and plain text extraction.\"\"\"\n",
    "\n",
    "    def extract_text(self, file: Union[Path, bytes]) -> str:\n",
    "        if isinstance(file, Path):\n",
    "            with open(file, \"rb\") as f:\n",
    "                reader = PdfReader(f)\n",
    "                return self._extract_all(reader)\n",
    "        elif isinstance(file, bytes):\n",
    "            from io import BytesIO\n",
    "            reader = PdfReader(BytesIO(file))\n",
    "            return self._extract_all(reader)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type for PDFParser.\")\n",
    "        \n",
    "    def _extract_all(self, reader: PdfReader) -> str:\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df3f5f",
   "metadata": {},
   "source": [
    "#### Agent Orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "335df8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../backend/app/core/agent_orchestrator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/agent_orchestrator.py\n",
    "\n",
    "# backend/app/core/agent_orchestrator.py\n",
    "from typing import Dict\n",
    "import time\n",
    "\n",
    "class AgentOrchestrator:\n",
    "    \"\"\"Handles agent pipeline for resume-JD matching.\"\"\"\n",
    "    def __init__(self):\n",
    "        # We will init agents here\n",
    "        pass\n",
    "\n",
    "    def run(self, job_type: str, data: Dict) -> Dict:\n",
    "        \"\"\"Executes the specified agent pipeline.\n",
    "        Args:\n",
    "            job_type: 'match', 'enhance', or 'cover_letter'\n",
    "            data: Dict with 'resume' and 'jd' (plain text)\n",
    "        Returns:\n",
    "            Dict with results\n",
    "        \"\"\"\n",
    "        time.sleep(2)\n",
    "        if job_type == \"match\":\n",
    "            return {\"status\": \"done\", \"result\": {\"match_score\": 85, \"insights\": \"Strong match for key requirements.\"}}\n",
    "        elif job_type == \"enhance\":\n",
    "            return {\"status\": \"done\", \"result\": {\"improvements\": \"Add more technical keywords from JD.\"}}\n",
    "        elif job_type == \"cover_letter\":\n",
    "            return {\"status\": \"done\", \"result\": {\"cover_letter\": \"Dear Hiring Manager, ...\"}}\n",
    "        else:\n",
    "            return {\"status\": \"error\", \"result\": {\"error\": \"Invalid job_type\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7fa43",
   "metadata": {},
   "source": [
    "### Job Queueing + Celery for distributed background job handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60e7c4d",
   "metadata": {},
   "source": [
    "#### Queueing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d9c337e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/core/async_queue.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/async_queue.py\n",
    "# backend/app/core/async_queue.py\n",
    "from backend.app.core.tasks import run_agent_job\n",
    "\n",
    "class AsyncJobQueueCelery:\n",
    "    \"\"\"Async job queue using Celery.\"\"\"\n",
    "    def submit_job(self, job_type: str, payload: dict) -> str:\n",
    "        celery_result = run_agent_job.delay(job_type, payload)\n",
    "        return celery_result.id\n",
    "    \n",
    "    def get_status(self, job_id: str) -> dict:\n",
    "        from celery.result import AsyncResult\n",
    "        from backend.worker.worker import celery_app\n",
    "        result = AsyncResult(job_id, app=celery_app)\n",
    "        status = result.status\n",
    "        value = result.result if result.successful() else None\n",
    "        return {\"status\": status, \"result\": value}\n",
    "    \n",
    "# Singleton\n",
    "queue = AsyncJobQueueCelery()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7bca06",
   "metadata": {},
   "source": [
    "#### Celery config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ce82233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/celeryconfig.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/celeryconfig.py\n",
    "# backend/celeryconfig.py\n",
    "\n",
    "# redis is in another docker container\n",
    "# if it's not the case for you,\n",
    "# use : \"redis://localhost:6379/0\"\n",
    "\n",
    "broker_url = \"redis://host.docker.internal:6379/0\"   \n",
    "result_backend = \"redis://host.docker.internal:6379/0\"\n",
    "task_serializer = \"json\"\n",
    "result_serializer = \"json\"\n",
    "accept_content = [\"json\"]\n",
    "timezone = \"UTC\"\n",
    "enable_utc = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088a8c16",
   "metadata": {},
   "source": [
    "#### Celery worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e13470b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/worker/worker.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/worker/worker.py\n",
    "# backend/worker/worker.py\n",
    "\n",
    "from celery import Celery\n",
    "\n",
    "celery_app = Celery(\"resume_jd_matcher\")\n",
    "celery_app.config_from_object(\"backend.celeryconfig\")\n",
    "\n",
    "import backend.app.core.tasks  # Ensure all tasks are registered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508076a0",
   "metadata": {},
   "source": [
    "#### Celery Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bac8c1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../backend/app/core/tasks.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/core/tasks.py\n",
    "# backend/app/core/tasks.py\n",
    "\n",
    "from backend.worker.worker import celery_app\n",
    "from backend.app.core.agent_orchestrator import AgentOrchestrator\n",
    "\n",
    "@celery_app.task(name=\"run_agent_job\")\n",
    "def run_agent_job(job_type: str, data: dict):\n",
    "    orchestrator = AgentOrchestrator()\n",
    "    result = orchestrator.run(job_type, data)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2d75e",
   "metadata": {},
   "source": [
    "### Backend api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2bde2",
   "metadata": {},
   "source": [
    "#### Data models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00fd2d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/models/job_models.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/models/job_models.py\n",
    "\n",
    "#backend/app/models/job_models.py\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, Dict\n",
    "\n",
    "class ResumeJDRequest(BaseModel):\n",
    "    resume: Optional[str] = None\n",
    "    jd: Optional[str] = None\n",
    "    job_type: str\n",
    "\n",
    "class PDFUploadResponse(BaseModel):\n",
    "    extracted_text: str\n",
    "\n",
    "class JobSubmitResponse(BaseModel):\n",
    "    job_id: str\n",
    "\n",
    "class JobStatusResponse(BaseModel):\n",
    "    status: str\n",
    "    result: Optional[Dict] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3553f032",
   "metadata": {},
   "source": [
    "#### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75847b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/api/routes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/api/routes.py\n",
    "#backend/app/api/routes.py\n",
    "\n",
    "from fastapi import APIRouter, File, UploadFile\n",
    "from backend.app.core.pdf_parser import PDFParser\n",
    "from backend.app.core.async_queue import queue\n",
    "from backend.app.models.job_models import(\n",
    "    ResumeJDRequest,\n",
    "    PDFUploadResponse,\n",
    "    JobSubmitResponse,\n",
    "    JobStatusResponse\n",
    ")\n",
    "\n",
    "\n",
    "api_router = APIRouter()\n",
    "\n",
    "@api_router.get(\"/health\", tags=[\"Health\"])\n",
    "def health_check():\n",
    "    return {\"status\": \"ok\"}\n",
    "\n",
    "@api_router.post(\"/parse-pdf\", response_model=PDFUploadResponse, tags=[\"Parsing\"])\n",
    "async def parse_pdf_endpoint(file: UploadFile = File(...)):\n",
    "    \"\"\"Extract text from uploaded PDF file.\"\"\"\n",
    "    content = await file.read()\n",
    "    parser = PDFParser()\n",
    "    try:\n",
    "        text = parser.extract_text(content)\n",
    "        return PDFUploadResponse(extracted_text=text)\n",
    "    except Exception as e:\n",
    "        return PDFUploadResponse(extracted_text=f\"Error: {str(e)}\")\n",
    "\n",
    "@api_router.post(\"/submit-job\", response_model=JobSubmitResponse, tags=[\"Jobs\"])\n",
    "async def submit_job(request: ResumeJDRequest):\n",
    "    \"\"\"Submit a matching/enhancing/cover letter job.\"\"\"\n",
    "    job_id = queue.submit_job(request.job_type, request.dict())\n",
    "    return JobSubmitResponse(job_id=job_id)\n",
    "\n",
    "@api_router.get(\"/job-status/{job_id}\", response_model=JobStatusResponse, tags=[\"Jobs\"])\n",
    "async def job_status(job_id: str):\n",
    "    status = queue.get_status(job_id)\n",
    "    return JobStatusResponse(**status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407815f",
   "metadata": {},
   "source": [
    "#### App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98164ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../backend/app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../backend/app/main.py\n",
    "#backend/app/main.py\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from backend.app.api.routes import api_router\n",
    "\n",
    "class JDMatcherApp:\n",
    "    def __init__(self):\n",
    "        self.app = FastAPI(\n",
    "            title=\"Resume-JD Matcher API\",\n",
    "            description=\"Backend for matching candidate resumes to job descriptions using AI agents.\",\n",
    "            version=\"0.1.0\"\n",
    "        )\n",
    "        self.include_routers()\n",
    "\n",
    "\n",
    "    def include_routers(self):\n",
    "        self.app.include_router(api_router)\n",
    "\n",
    "def get_app():\n",
    "    \"\"\"Entrypoint for ASGI\"\"\"\n",
    "    return JDMatcherApp().app\n",
    "\n",
    "# Run with 'uvicorn backend.app.main:get_app'\n",
    "app = get_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c37969",
   "metadata": {},
   "source": [
    "## **`Frontend`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba83835",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume-jd-matcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
